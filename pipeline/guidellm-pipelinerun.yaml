apiVersion: tekton.dev/v1
kind: PipelineRun
metadata:
  name: guidellm-benchmark-run
spec:
  pipelineRef:
    name: guidellm-benchmark-pipeline
  workspaces:
    - name: shared-workspace
      persistentVolumeClaim:
        claimName: guidellm-output-pvc
  params:
    - name: target
      value: "http://llama32-3b.llama-serve.svc.cluster.local:8000/v1"
    - name: model-name
      value: "llama32-3b"
    - name: processor
      value: "RedHatAI/Llama-3.2-3B-Instruct-quantized.w8a8"
    - name: data-config
      value: '{"type":"emulated","prompt_tokens":512,"output_tokens":128}'
    - name: max-seconds
      value: "1800"
    - name: rate-type
      value: "synchronous"
    - name: api-key
      value: "f2f1423XXXXXXXXXXX8f39b6a3e5b25"
    - name: max-concurrency
      value: "10"
    - name: huggingface-token
      value: "your-huggingface-token-here"